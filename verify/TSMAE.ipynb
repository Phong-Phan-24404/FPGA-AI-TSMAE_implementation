{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":5626903,"sourceType":"datasetVersion","datasetId":3235299}],"dockerImageVersionId":30918,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import torch\nimport torch.nn as nn\nimport torch.optim as optim\nfrom tqdm import tqdm\nimport numpy as np\nimport pandas as pd\nfrom torch.utils.data import Dataset, DataLoader\nimport scipy.io.arff as arff\nimport matplotlib.pyplot as plt\n\n# ---------------------------\n# Dataset Definition (ECG5000)\n# ---------------------------\nclass ECG5000(Dataset):\n    def __init__(self, mode, split='train', seq_len=10):\n        assert mode in ['normal', 'anomaly', 'all']\n        assert split in ['train', 'test']\n        self.seq_len = seq_len\n\n        if split == 'train':\n            file_path = '/kaggle/input/ecg50000/ECG5000_TRAIN.arff'\n        else:\n            file_path = '/kaggle/input/ecg50000/ECG5000_TEST.arff'\n\n        data, meta = arff.loadarff(file_path)\n        df = pd.DataFrame(data, columns=meta.names())\n        new_columns = list(df.columns)\n        new_columns[-1] = 'target'\n        df.columns = new_columns\n\n        if mode == 'normal':\n            df = df[df.target == b'1'].drop(labels='target', axis=1)\n        elif mode == 'anomaly':\n            df = df[df.target != b'1'].drop(labels='target', axis=1)\n        else:\n            df = df.drop(labels='target', axis=1)\n\n        raw_data = df.astype(np.float32).to_numpy()\n        \n        # Cắt thành các đoạn có độ dài seq_len\n        self.X = []\n        for series in raw_data:\n            for i in range(0, len(series) - seq_len + 1, seq_len):  # hoặc bước 1 nếu muốn sliding window\n                self.X.append(series[i:i+seq_len])\n        self.X = np.array(self.X)\n\n    def __getitem__(self, index):\n        return torch.from_numpy(self.X[index]).unsqueeze(-1)  # (seq_len, 1)\n\n    def __len__(self):\n        return len(self.X)\n\n\n\nclass MemoryModule(nn.Module):\n    def __init__(self, memory_size, hidden_size, sparsity_threshold=0.05):\n        \"\"\"\n        memory_size: Number of memory items.\n        hidden_size: Dimensionality of each memory item.\n        sparsity_threshold: Threshold for rectifying the addressing vector.\n        \"\"\"\n        super(MemoryModule, self).__init__()\n        self.memory_size = memory_size\n        self.hidden_size = hidden_size\n        self.sparsity_threshold = sparsity_threshold\n        # Initialize learnable memory items.\n        self.memory = nn.Parameter(torch.randn(memory_size, hidden_size))\n    \n    def forward(self, z):\n        \"\"\"\n        z: latent representation from encoder with shape (batch, hidden_size)\n        Returns:\n          z_hat: recombined latent representation from memory.\n          q: sparse addressing vector with shape (batch, memory_size)\n        \"\"\"\n\n        # Compute similarity scores between latent vector and memory items.\n        sim = torch.matmul(z, self.memory.t())  # shape: (batch, memory_size)\n        # Softmax to obtain addressing weights.\n        q = nn.functional.softmax(sim, dim=1)\n        # Rectify: subtract threshold and zero out negatives.\n        q = torch.max(q - self.sparsity_threshold, torch.zeros_like(q))\n        # Normalize so that each row sums to 1.\n        q = q / (q.sum(dim=1, keepdim=True) + 1e-8)\n        # Recombine memory items.\n        z_hat = torch.matmul(q, self.memory)\n        return z_hat, q\n\n# ---------------------------\n# TSMAE Model Definition\n# ---------------------------\nclass TSMAE(nn.Module):\n    def __init__(self, input_size, hidden_size, memory_size, sparsity_threshold=0.05, sparsity_factor=0.001):\n        \"\"\"\n        input_size: Dimension of each time step (e.g., 1)\n        hidden_size: Dimension of the latent representation\n        memory_size: Number of memory items.\n        sparsity_threshold: Threshold used in the memory module.\n        sparsity_factor: Weight for the sparsity penalty in the loss.\n        \"\"\"\n        super(TSMAE, self).__init__()\n        self.input_size = input_size\n        self.hidden_size = hidden_size\n        self.memory_size = memory_size\n        self.sparsity_factor = sparsity_factor\n        \n        # LSTM Encoder: encodes input sequence into a latent vector.\n        self.encoder = nn.LSTM(input_size, hidden_size, batch_first=True)\n        # Memory Module: extracts typical normal patterns.\n        self.memory_module = MemoryModule(memory_size, hidden_size, sparsity_threshold)\n        # LSTM Decoder: decodes the latent representation back to sequence.\n        self.decoder = nn.LSTM(hidden_size, hidden_size, batch_first=True)\n        # Final layer to project the LSTM decoder output to the input space.\n        self.output_layer = nn.Linear(hidden_size, input_size)\n        \n    def forward(self, x):\n        \"\"\"\n        x: Input tensor of shape (batch, seq_len, input_size)\n        Returns:\n          x_recon: Reconstructed sequence of shape (batch, seq_len, input_size)\n          q: Sparse addressing vector from the memory module (batch, memory_size)\n          z: Latent representation from the encoder (batch, hidden_size)\n          z_hat: Recombined latent representation from the memory module (batch, hidden_size)\n        \"\"\"\n        batch_size, seq_len, _ = x.size()\n        # Encode input sequence.\n        enc_out, (h_n, c_n) = self.encoder(x)\n        z = h_n[-1]  # Use the final hidden state; shape: (batch, hidden_size)\n        \n        # Pass through memory module.\n        z_hat, q = self.memory_module(z)\n        \n        # For decoding, repeat z_hat across the sequence length.\n        z_hat_seq = z_hat.unsqueeze(1).repeat(1, seq_len, 1)\n        dec_out, _ = self.decoder(z_hat_seq)\n        # Project decoder output back to input dimension.\n        x_recon = self.output_layer(dec_out)\n        return x_recon, q, z, z_hat\n\n    def loss_function(self, x, x_recon, q):\n        # Mean Squared Error reconstruction loss.\n        rec_loss = torch.mean((x - x_recon)**2)\n        # Sparsity loss to encourage a sparse addressing vector.\n        sparsity_loss = torch.mean(torch.log(1 + q**2))\n        loss = rec_loss + self.sparsity_factor * sparsity_loss\n        return loss, rec_loss, sparsity_loss\n\n# ---------------------------\n# Training Setup\n# ---------------------------\ndef train_model(model, dataloader, optimizer, device, num_epochs=50):\n    model.to(device)\n    model.train()\n    train_losses = []\n    for epoch in range(num_epochs):\n        epoch_loss = 0.0\n        for batch in tqdm(dataloader, desc=f\"Epoch {epoch+1}/{num_epochs}\"):\n            batch = batch.to(device)\n            optimizer.zero_grad()\n            x_recon, q, z, z_hat = model(batch)\n            loss, rec_loss, sparsity_loss = model.loss_function(batch, x_recon, q)\n            loss.backward()\n            optimizer.step()\n            epoch_loss += loss.item() * batch.size(0)\n        avg_loss = epoch_loss / len(dataloader.dataset)\n        train_losses.append(avg_loss)\n        print(f\"Epoch {epoch+1} Loss: {avg_loss:.6f}\")\n    return train_losses\n\n# ---------------------------\n# Main Execution\n# ---------------------------\nif __name__ == '__main__':\n    # Hyperparameters.\n    input_size = 1           # Each time step has 1 feature.\n    hidden_size = 10         # Latent representation dimension.\n    memory_size = 10         # Number of memory items.\n    sparsity_threshold = 0.05\n    sparsity_factor = 0.001\n    batch_size = 1\n    num_epochs = 100\n    learning_rate = 1e-3\n\n    # ---------------------------\n    # Training: Use the TRAIN file with both normal and anomaly samples.\n    # ---------------------------\n    train_dataset = ECG5000(mode='all', split='train', seq_len=10)\n    train_loader = DataLoader(train_dataset, batch_size=1, shuffle=True, drop_last=True)\n    \n    # Initialize the TSMAE model.\n    model = TSMAE(input_size, hidden_size, memory_size, sparsity_threshold, sparsity_factor)\n    optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n\n    # Check for available device.\n    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n    print(\"Training on device:\", device)\n\n    # Train the model.\n    train_losses = train_model(model, train_loader, optimizer, device, num_epochs=num_epochs)\n\n    # Plot training loss.\n    plt.figure(figsize=(8, 4))\n    plt.plot(train_losses, label='Training Loss')\n    plt.xlabel(\"Epoch\")\n    plt.ylabel(\"Loss\")\n    plt.legend()\n    plt.title(\"Training Loss vs Epochs\")\n    plt.show()\n\n\n    # ---------------------------\n    # Evaluation: Use the TEST file with both normal and anomaly samples.\n    # ---------------------------\n    test_dataset = ECG5000(mode='all', split='test', seq_len=10)\n    test_loader = DataLoader(test_dataset, batch_size=1, shuffle=False)\n\n    model.eval()\n    total_test_loss = 0.0\n    with torch.no_grad():\n        for batch in test_loader:\n            batch = batch.to(device)\n            x_recon, q, z, z_hat = model(batch)\n            loss, rec_loss, sparsity_loss = model.loss_function(batch, x_recon, q)\n            total_test_loss += loss.item() * batch.size(0)\n    avg_test_loss = total_test_loss / len(test_loader.dataset)\n    print(f\"Average test loss on TEST file: {avg_test_loss:.6f}\")\n\n    # ---------------------------\n    # Plotting Reconstruction Comparisons (TEST file)\n    # ---------------------------\n    # Evaluate one normal sample from the test file.\n    normal_dataset_eval = ECG5000(mode='normal', split='test', seq_len=10)\n    anomaly_dataset_eval = ECG5000(mode='anomaly', split='test', seq_len=10)\n\n    with torch.no_grad():\n        normal_recon, normal_q, _, _ = model(normal_sample)\n    normal_series_np = normal_sample.cpu().numpy().flatten()\n    normal_recon_np = normal_recon.cpu().numpy().flatten()\n\n    # Evaluate one anomaly sample from the test file.\n    anomaly_dataset_eval = ECG5000(mode='anomaly', split='test')\n    anomaly_sample = anomaly_dataset_eval[0].unsqueeze(0).to(device)\n    with torch.no_grad():\n        anomaly_recon, anomaly_q, _, _ = model(anomaly_sample)\n    anomaly_series_np = anomaly_sample.cpu().numpy().flatten()\n    anomaly_recon_np = anomaly_recon.cpu().numpy().flatten()\n\n    # Plot normal sample reconstruction.\n    plt.figure(figsize=(12, 5))\n    plt.subplot(1, 2, 1)\n    plt.plot(normal_series_np, label=\"Original Normal\")\n    plt.plot(normal_recon_np, label=\"Reconstructed Normal\", linestyle=\"--\")\n    plt.title(\"Normal Sample Reconstruction (TEST file)\")\n    plt.xlabel(\"Time Step\")\n    plt.ylabel(\"Value\")\n    plt.legend()\n\n    # Plot anomaly sample reconstruction.\n    plt.subplot(1, 2, 2)\n    plt.plot(anomaly_series_np, label=\"Original Anomaly\")\n    plt.plot(anomaly_recon_np, label=\"Reconstructed Anomaly\", linestyle=\"--\")\n    plt.title(\"Anomaly Sample Reconstruction (TEST file)\")\n    plt.xlabel(\"Time Step\")\n    plt.ylabel(\"Value\")\n    plt.legend()\n    plt.show()","metadata":{"_uuid":"a125eb3d-a63d-4707-afd1-97b341a88f23","_cell_guid":"b44838ef-86b1-4be7-83ef-45d58276e0ef","trusted":true,"collapsed":false,"execution":{"iopub.status.busy":"2025-06-21T12:17:08.064670Z","iopub.execute_input":"2025-06-21T12:17:08.065036Z"},"jupyter":{"outputs_hidden":false}},"outputs":[],"execution_count":null}]}